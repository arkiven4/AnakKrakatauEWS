{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDSN Waveform Downloader, Converter & Detector\n",
    "\n",
    "Downloads I06AU and I52GB waveforms from IRIS FSDN services using Obpsy Mass Downloader and then converts them the .SAC file with it's stats for further processing. The .SAC files will be then further processed using \"Bartlett\" beamforming method and Adaptive F-Detector to identify signals most related to Anak Krakatau Volcanic Activity. These specific volcanic activity signals will be later ingested into the algorithm for the Deep Learning processing\n",
    "\n",
    "This notebook consists of 3 parts:\n",
    "1. Dowloading Data using Obspy Mass Downloader\n",
    "2. Conversion of MSEED Files to .SAC\n",
    "3. Conversion of .SAC files to CSV\n",
    "4. Implementing FK Beamforming to each station group\n",
    "5. Running Adaptive F-Detector to Isolate relevant Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/')\n",
    "\n",
    "import obspy\n",
    "from obspy import UTCDateTime, read, read_inventory\n",
    "from obspy.clients.fdsn.mass_downloader import GlobalDomain, \\\n",
    "    Restrictions, MassDownloader\n",
    "from obspy.core.util.attribdict import AttribDict\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Downloading Data Using Obspy Mass Downloader\n",
    "\n",
    "Download the data ranging from 2018-06-24T00:00:00 until 2019-09-03T00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 I06AU Waveform Download\n",
    "\n",
    "domain = GlobalDomain()\n",
    "\n",
    "restrictions = Restrictions(\n",
    "    # Get data for a whole year.\n",
    "    starttime=obspy.UTCDateTime(2018, 6, 24),\n",
    "    endtime=obspy.UTCDateTime(2019, 9, 3),\n",
    "    # Chunk it to have one file per day.\n",
    "    chunklength_in_sec=86400,\n",
    "    network=\"IM\", station=\"I06H*\", location=\"\", channel=\"BDF\",\n",
    "    # The typical use case for such a data set are noise correlations where\n",
    "    # gaps are dealt with at a later stage.\n",
    "    reject_channels_with_gaps=False,\n",
    "    # Same is true with the minimum length. All data might be useful.\n",
    "    minimum_length=0.0,\n",
    "    # Guard against the same station having different names.\n",
    "    minimum_interstation_distance_in_m=100.0)\n",
    "\n",
    "mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "mdl.download(domain, restrictions, mseed_storage=\"waveform_collection/I06AU/WAVEFORM_I06AU_MSEED\",\n",
    "             stationxml_storage=\"waveform_collection/I06AU/I06AU_STATIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 I52GB Waveform Download\n",
    "\n",
    "domain = GlobalDomain()\n",
    "\n",
    "restrictions = Restrictions(\n",
    "    starttime=obspy.UTCDateTime(2018, 6, 24),\n",
    "    endtime=obspy.UTCDateTime(2019, 9, 3),\n",
    "    chunklength_in_sec=86400,\n",
    "    network=\"IM\", station=\"I52H*\", location=\"\", channel=\"BDF\",\n",
    "    reject_channels_with_gaps=False,\n",
    "    minimum_length=0.0,\n",
    "    minimum_interstation_distance_in_m=100.0)\n",
    "\n",
    "\n",
    "mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "mdl.download(domain, restrictions, mseed_storage=\"waveform_collection/I52GB/WAVEFORM_I52GB_MSEED\",\n",
    "             stationxml_storage=\"waveform_collection/I52GB/I52GB_STATIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conversion of MSEED Files to .SAC\n",
    "Converting MSEED Files to SAC Complete with Important Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 I06AU Waveform Conversion\n",
    "\n",
    "input_directory = 'waveform_collection/I06AU/WAVEFORM_I06AU_MSEED'\n",
    "output_directory = 'waveform_collection/I06AU/WAVEFORM_I06AU_SAC'\n",
    "stationxml_directory = 'waveform_collection/I06AU/I06AU_STATIONS'\n",
    "\n",
    "# Run the Function\n",
    "mseed_to_sac(input_directory, output_directory, stationxml_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 I52GB Waveform Conversion\n",
    "\n",
    "input_directory = 'waveform_collection/I52GB/WAVEFORM_I52GB_MSEED'\n",
    "output_directory = 'waveform_collection/I52GB/WAVEFORM_I52GB_SAC'\n",
    "stationxml_directory = 'waveform_collection/I52GB/I52GB_STATIONS'\n",
    "\n",
    "# Run the Function\n",
    "mseed_to_sac(input_directory, output_directory, stationxml_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conversion of SAC files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "CSV file created at: /run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_CSV/IM.I06H_..BDF__20180625T000000Z__20180626T000000Z.csv\n",
      "CSV file created at: /run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_CSV/IM.I06H_..BDF__20180626T000000Z__20180627T000000Z.csv\n",
      "CSV file created at: /run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_CSV/IM.I06H_..BDF__20180624T000000Z__20180625T000000Z.csv\n"
     ]
    }
   ],
   "source": [
    "# 3.1 I06AU SAC to csv conversion\n",
    "\n",
    "folder_path = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_SAC'\n",
    "output_folder = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_CSV'\n",
    "freqmin = 0.7 \n",
    "freqmax = 4.0 \n",
    "df_grouped_file_paths = sac_path_grouping(folder_path)\n",
    "\n",
    "# Iterate over the DataFrame rows and process each file path\n",
    "for index, row in df_grouped_file_paths.iterrows():\n",
    "    file_path_pattern = row['GroupedFilePath']\n",
    "    try:\n",
    "        # Process each file path pattern with the sac_to_csv function\n",
    "        csv_output_path = sac_to_csv(file_path_pattern, output_folder, freqmin, freqmax)\n",
    "        print(f'CSV file created at: {csv_output_path}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file pattern {file_path_pattern}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 I52GB SAC to csv conversion\n",
    "\n",
    "folder_path = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_SAC'\n",
    "output_folder = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_CSV'\n",
    "freqmin = 0.7 \n",
    "freqmax = 4.0 \n",
    "df_grouped_file_paths = sac_path_grouping(folder_path)\n",
    "\n",
    "# Iterate over the DataFrame rows and process each file path\n",
    "for index, row in df_grouped_file_paths.iterrows():\n",
    "    file_path_pattern = row['GroupedFilePath']\n",
    "    try:\n",
    "        # Process each file path pattern with the sac_to_csv function\n",
    "        csv_output_path = sac_to_csv(file_path_pattern, output_folder, freqmin, freqmax)\n",
    "        print(f'CSV file created at: {csv_output_path}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file pattern {file_path_pattern}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running Beamforming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Running Beamforming on I06AU Waveform\n",
    "\n",
    "base_folder_path = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_SAC'\n",
    "df_grouped_file_paths = sac_path_grouping(base_folder_path)\n",
    "\n",
    "# Wrap the iterrows with tqdm to create a progress bar\n",
    "for index, row in tqdm(df_grouped_file_paths.iterrows(), total=df_grouped_file_paths.shape[0], desc=\"Processing\"):\n",
    "    # Construct the full path to the grouped files\n",
    "    full_grouped_path = f\"{base_folder_path}/{row['GroupedFilePath']}\"\n",
    "\n",
    "    # Prepare the CLI command\n",
    "    cli_command = f\"infrapy run_fk --local-wvfrms \\\"{full_grouped_path}\\\" --\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the CLI command\n",
    "        subprocess.run(cli_command, shell=True, check=True)\n",
    "        print(f\"Command executed for: {full_grouped_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running the command for {full_grouped_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Running Beamforming on I52GB Waveform\n",
    "\n",
    "base_folder_path = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I52GB/WAVEFORM_I52GB_SAC'\n",
    "df_grouped_file_paths = sac_path_grouping(base_folder_path)\n",
    "\n",
    "# Wrap the iterrows with tqdm to create a progress bar\n",
    "for index, row in tqdm(df_grouped_file_paths.iterrows(), total=df_grouped_file_paths.shape[0], desc=\"Processing\"):\n",
    "    # Construct the full path to the grouped files\n",
    "    full_grouped_path = f\"{base_folder_path}/{row['GroupedFilePath']}\"\n",
    "\n",
    "    # Prepare the CLI command\n",
    "    cli_command = f\"infrapy run_fk --local-wvfrms \\\"{full_grouped_path}\\\" --\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the CLI command\n",
    "        subprocess.run(cli_command, shell=True, check=True)\n",
    "        print(f\"Command executed for: {full_grouped_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running the command for {full_grouped_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infrapy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
